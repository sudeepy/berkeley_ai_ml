{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7167366d8ddbc65b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Required Assignment 6.3: Running PCA with Clustering\n",
    "\n",
    "**Expected Time = 120 minutes**\n",
    "\n",
    "**Total Points = 36**\n",
    "\n",
    "Now that you've seen how to use PCA to reduce the dimensionality of data while maintaining important information, it is time to see how we can use these ideas applied to a real dataset. In this activity, you will use a dataset related to marketing campaigns, with the task of identifying groups of similar customers.  Once the cluster labels are assigned, you will briefly explore inside of each cluster for patterns that help identify characteristics of customers.\n",
    "\n",
    "## Index:\n",
    "\n",
    "- [Problem 1](#Problem-1)\n",
    "- [Problem 2](#Problem-2)\n",
    "- [Problem 3](#Problem-3)\n",
    "- [Problem 4](#Problem-4)\n",
    "- [Problem 5](#Problem-5)\n",
    "- [Problem 6](#Problem-6)\n",
    "- [Problem 7](#Problem-7)\n",
    "- [Problem 8](#Problem-8)\n",
    "- [Problem 9](#Problem-9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0398b6ff2cbb6afa",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### The Dataset\n",
    "\n",
    "More information on the dataset can be found [here](https://www.kaggle.com/imakash3011/customer-personality-analysis).  Below, the data is loaded, the info is displayed, the continuous features are described, and the first five rows of the data are displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/marketing_campaign.csv', sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-dca63149748a8309",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#Index:)\n",
    "\n",
    "## Problem 1\n",
    "\n",
    "### Preparing the Data\n",
    "\n",
    "**4 Points**\n",
    "\n",
    "Before starting to build cluster models, the data needs to be limited to numeric representations.  How many non-numeric columns are there, and what are their names?  Assign your solution as a list of strings to `object_cols` below.  The names should match the column names in the DataFrame exactly.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e927ed55d22e65c7",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "\n",
    "object_cols = ''\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "object_cols = df.select_dtypes('object').columns.tolist()\n",
    "### END SOLUTION\n",
    "\n",
    "# Answer check\n",
    "print(object_cols)\n",
    "print(type(object_cols))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5e4026a92bc409c8",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#Index:)\n",
    "\n",
    "## Problem 2\n",
    "\n",
    "### Dropping the `object` columns \n",
    "\n",
    "**4 Points**\n",
    "\n",
    "To simplify things, eliminate the columns containing `object` datatypes.  Assign your new DataFrame to `df_numeric` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0cf63a5c006edff3",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "\n",
    "df_numeric = ''\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "object_cols = df.select_dtypes('object').columns.tolist()\n",
    "df_numeric = df.drop(object_cols, axis = 1)\n",
    "### END SOLUTION\n",
    "\n",
    "# Answer check\n",
    "print(df_numeric.shape)\n",
    "df_numeric.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4a863e362e2e1b86",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#Index:)\n",
    "\n",
    "## Problem 3\n",
    "\n",
    "### Dropping non-informative columns\n",
    "\n",
    "**4 Points**\n",
    "\n",
    "Two columns, `Z_CostContact`, and `Z_Revenue` have one unique value. Also, the `ID` column is basically an index. These will not add any information to our problem. Drop the columns `Z_CostContact`, `Z_Revenue`, and `ID` and save your all numeric data without these two columns as a DataFrame to `df_clean` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-90ad2448a7dad12c",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "\n",
    "df_clean = ''\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "object_cols = df.select_dtypes('object').columns.tolist() + ['ID', 'Z_CostContact', 'Z_Revenue']\n",
    "df_clean = df.drop(object_cols, axis = 1)\n",
    "### END SOLUTION\n",
    "\n",
    "# Answer check\n",
    "print(df_clean.shape)\n",
    "df_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-cc73ab51b9a8e65e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#Index:)\n",
    "\n",
    "## Problem 4\n",
    "\n",
    "### Dropping the missing data\n",
    "\n",
    "**4 Points**\n",
    "\n",
    "Note that the `Income` column is missing data.  This will cause issues for `PCA` and clustering algorithms.  Drop the missing data using pandas `.dropna` method on `df_clean`, and assign your non-missing dataset as a DataFrame to `df_clean_nona` below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5f889dbf691b2c65",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "\n",
    "df_clean_nona = ''\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "object_cols = df.select_dtypes('object').columns.tolist() + ['ID', 'Z_CostContact', 'Z_Revenue']\n",
    "df_clean = df.drop(object_cols, axis = 1)\n",
    "df_clean_nona = df_clean.dropna()\n",
    "### END SOLUTION\n",
    "\n",
    "# Answer check\n",
    "print(df_clean_nona.shape)\n",
    "df_clean_nona.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-78521133f1bf38af",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#Index:)\n",
    "\n",
    "## Problem 5\n",
    "\n",
    "### Scaling the Data\n",
    "\n",
    "**4 Points**\n",
    "\n",
    "As earlier with the PCA models, the data needs to be mean-centered.  \n",
    "\n",
    "\n",
    "Below, scale the `df_clean_nona` by subtracting its mean and by dividing it by its standard deviation.  Assign your results as a DataFrame to `df_scaled` below.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-569f6bf865d28c94",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "\n",
    "df_scaled = ''\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "df_scaled = (df_clean_nona - df_clean_nona.mean())/df_clean_nona.std()\n",
    "### END SOLUTION\n",
    "\n",
    "# Answer check\n",
    "print(df_scaled.shape)\n",
    "print(type(df_scaled))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-076894ed50ce8a92",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#Index:)\n",
    "\n",
    "## Problem 6\n",
    "\n",
    "### PCA\n",
    "\n",
    "**4 Points**\n",
    "\n",
    "With the data cleaned and scaled, you are ready to perform PCA.  Below, use the `PCA` transformer from `sklearn` to transform your data and select the top three principal components.  First, create an instance of the `PCA` that limits the number of components to 3 using the `n_components` argument.  Also, set the argument `random_state = 42`  and assign your instance as `pca` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-171e685ec9f0396e",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "\n",
    "pca = ''\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "pca = PCA(n_components=3, random_state=42)\n",
    "### END SOLUTION\n",
    "\n",
    "# Answer check\n",
    "print(pca)\n",
    "print(pca.n_components)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-572ec866d9db54b2",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#Index:)\n",
    "\n",
    "## Problem 7\n",
    "\n",
    "### Extracting the Components\n",
    "\n",
    "**4 Points**\n",
    "\n",
    "Use the `.fit_transform` method with the argument equal to `df_scaled` on `pca` to extract the three principal components.  Save these components as an array to the variable `components` below.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ccb759ef1b3655ca",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "\n",
    "components = ''\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "pca = PCA(n_components=3, random_state = 42)\n",
    "components = pca.fit_transform(df_scaled)\n",
    "### END SOLUTION\n",
    "\n",
    "# Answer check\n",
    "print(type(components))\n",
    "print(components.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-87616ec28fd827b5",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#Index:)\n",
    "\n",
    "## Problem 8\n",
    "\n",
    "### `KMeans`\n",
    "\n",
    "**4 Points**\n",
    "Complete the code below according to the instructions below:\n",
    "\n",
    "\n",
    "- To the `kmeans` variable, assign the `KMeans` clusterer with the argument `n_clusters` equal to `3` and the argument `random_state` equal to `42`. To this, chain the `fit()` method with the argument equal to `components`.\n",
    "- Copy the code line that reads the data  in your solution code.\n",
    "- Copy the code to drop the missing value in your solution. Here, inside the `dropna()` function, set the argument `subset` equal to `['Income']`.\n",
    "- Inside `df_clustered`, create a new column `cluster`. To this column, assign `kmeans.labels_`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0bd42978a0345d53",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "\n",
    "kmeans = ''\n",
    "df = pd.read_csv('data/marketing_campaign.csv', sep = '\\t')\n",
    "df_clustered = df.dropna()\n",
    "df_clustered['cluster'] = ''\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "kmeans = KMeans(n_clusters=3, random_state=42).fit(components)\n",
    "df = pd.read_csv('data/marketing_campaign.csv', sep = '\\t')\n",
    "df_clustered = df.dropna(subset = ['Income'])\n",
    "df_clustered['cluster'] = kmeans.labels_\n",
    "### END SOLUTION\n",
    "\n",
    "# Answer check\n",
    "print(type(df_clustered))\n",
    "print(df_clustered.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-af83b79c548a1e36",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#Index:)\n",
    "\n",
    "## Problem 9\n",
    "\n",
    "### Examining the Results\n",
    "\n",
    "**4 Points**\n",
    "\n",
    "The image below shows a `boxenplot` of the clusters based on amounts spent on meat products.  If you were marketing a meat sale and there is a cost involved in advertisiting per customer.  If you were to select only one cluster to market to, which cluster would you target? Assign your response as an integer to `target_cluster` below.\n",
    "\n",
    "![](images/meats.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c64b2384ee8cd54f",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "\n",
    "target_cluster = ''\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "target_cluster = 1\n",
    "### END SOLUTION\n",
    "\n",
    "# Answer check\n",
    "print(type(target_cluster))\n",
    "print(target_cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ce270829ea1f18cf",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "While this is a start, there is much more work to be done.  We glossed over perhaps one of the most important parts of the task -- feature engineering.  Some of the columns that were objects could be represented numerically.  Also, we could try different numbers of components from PCA and numbers of clusters.  In a business setting, it is important to keep the number of clusters small so that the groups can be distinguished in meaningful ways, so we don't want to let the number of clusters get too large.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-8892f1989cfb4fe4",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Required Assignment 10.4: Time Series and Sales\n",
    "\n",
    "**Expected Time = 60 minutes** \n",
    "\n",
    "**Total Points = 50** \n",
    "\n",
    "This activity is meant to extend your work with ARMA models to apply a forecasting model across stores in a retail chain, as well as items in each store.  You will build models for each store for a specific item and compare this forecast to the model, aggregating all stores.  Also, you will compare a model for sales by store for all items and discuss expected performance for each store according to your forecast.  \n",
    "\n",
    "In addition to the ARMA models, you will explore an extension of this to include seasonality elements with the SARIMA model.  Both are implemented with `statsmodels`.   \n",
    "\n",
    "#### Index\n",
    "\n",
    "- [Problem 1](#-Problem-1)\n",
    "- [Problem 2](#-Problem-2)\n",
    "- [Problem 3](#-Problem-3)\n",
    "- [Problem 4](#-Problem-4)\n",
    "- [Problem 5](#-Problem-5)\n",
    "- [Problem 6](#-Problem-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.tsa.stattools import acf, pacf\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from warnings import filterwarnings \n",
    "filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-34ef0513619e8d1c",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### The Data\n",
    "\n",
    "The data is from a past time series competition on Kaggle [here](https://www.kaggle.com/c/demand-forecasting-kernels-only).  It represents historical sales across 10 stores of 50 items.  Each observation is a day's total sales by store and item.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/train.csv.zip', compression = 'zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b9f328f21938b9da",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 1\n",
    "\n",
    "#### Structuring the data and time series\n",
    "\n",
    "**5 Points**\n",
    "\n",
    "To begin, notice that the DataFrame `df` does not have a datetime index.  Below, convert the `date` column to a datetime object and set it as the index to a new DataFrame called `stores_df` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5deb9824ac158da1",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "\n",
    "stores_df = ''\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "stores_df = df.set_index(pd.to_datetime(df['date'])).drop('date', axis = 1)\n",
    "### END SOLUTION\n",
    "\n",
    "# Answer check\n",
    "print(stores_df.head())\n",
    "print('------------\\nData Info\\n')\n",
    "print(stores_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0f808f90f44e8442",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 2\n",
    "\n",
    "#### Store 1 Model\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "In anticipation of building a 30-day forecast for sales of item 1 in store 1, subset the data to only the sales column for item 1 store 1 and assign as a DataFrame to `store_1_item_1` below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-3d289635c9a06377",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "\n",
    "store_1_item_1 = ''\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "store_1_item_1 = stores_df[(stores_df['store'] == 1) & (stores_df['item'] == 1)][['sales']]\n",
    "### END SOLUTION\n",
    "\n",
    "# Answer check\n",
    "print(store_1_item_1.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b6fb248f431c5045",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 3\n",
    "\n",
    "#### Train/Test split\n",
    "\n",
    "**5 Points**\n",
    "\n",
    "Now, use the store 1 data from the previous question to create a train-test split where `train_data` is all but the last 30 days of sales data.  You no longer need the store and item columns.  Assign these values as `X_train` and `X_test` respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-28d1ca852d462b8e",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "\n",
    "X_train, X_test = '', ''\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "X_train, X_test = store_1_item_1.iloc[:-30], store_1_item_1.iloc[-30:]\n",
    "### END SOLUTION\n",
    "\n",
    "# Answer check\n",
    "print(X_train.tail())\n",
    "print(X_test.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7b2ff3288a6cceea",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 4\n",
    "\n",
    "#### Assumptions of Linearity\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "Next, you will want to check the assumptions of our model before building it.  Specifically, this was the notion that our time series is stationary for the ARMA models.  Use the `adfuller` function to determine if the series is stationary.  Assign the $p$ value to `pval` below.  Consider your threshold at $p = 0.01$.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c7330ba1e6de60fd",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "\n",
    "pval = ''\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "pval = adfuller(X_train)[1]\n",
    "### END SOLUTION\n",
    "\n",
    "# Answer check\n",
    "print(f'The p-value is {pval: .4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5ed4ecbaef34dd2d",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 5\n",
    "\n",
    "#### Autocorrelation and Partial Autocorrelation\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "Backing up the results of our hypothesis test, the autocorrelation of the original series seems to not be stationary.  Instead, the differenced data and its ACF and PACF plot look better.  We will begin by using these plots to suggest an `order = (1, 0, 1)` model based on the differenced data.  Accordingly, build an `ARIMA` model with `order = (1, 0, 1)` and fit on the training data and assign to `arma` below.\n",
    "\n",
    "Determine the mean squared error on the test data and assign as a float to `mse_test` below.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 4, figsize = (20, 5))\n",
    "plot_acf(df[(df['store'] == 1) & (df['item'] == 1)]['sales'], ax = ax[0]);\n",
    "ax[0].set_title('Original Series Autocorrelation')\n",
    "plot_acf(df[(df['store'] == 1) & (df['item'] == 1)]['sales'].diff().dropna(), ax = ax[1]);\n",
    "ax[1].set_title('Differenced Autocorrelation')\n",
    "plot_pacf(df[(df['store'] == 1) & (df['item'] == 1)]['sales'].diff().dropna(), ax = ax[2], method = 'ywm');\n",
    "ax[3].plot(df[(df['store'] == 1) & (df['item'] == 1)]['sales'].diff().dropna())\n",
    "ax[3].set_title('Differenced Sales Series');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-61c766c82e59e0ca",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "arma = ARIMA(X_train.diff(), order = (1, 0, 1), freq = 'D').fit()\n",
    "preds = arma.forecast(len(X_test))\n",
    "mse_test = mean_squared_error(preds, X_test)\n",
    "### END SOLUTION\n",
    "\n",
    "### ANSWER CHECK\n",
    "print(preds[:5])\n",
    "print(mse_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(arma.forecast(steps = len(X_test)), label = 'forecast')\n",
    "# plt.plot(X_test.diff(), label = 'Differenced Series')\n",
    "# plt.title('Comparing the Forecast')\n",
    "# plt.legend();\n",
    "# plt.xticks(rotation = 60)\n",
    "# plt.grid();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e94527ce68e7b2c7",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 6\n",
    "\n",
    "#### A Model with Seasonality\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "As discussed with the decomposition models earlier, there are ways to consider a seasonal oscillation within the data.  For ARIMA a version that adds a seasonal element is called SARIMA.  In statsmodels, we use the `SARIMAX` estimator to build this model that includes seasonal elements.\n",
    "\n",
    "Much like the decomposition model, you can have a multiplicative or additive seasonality.  For a multiplicative seasonal effect that we determine is yearly we add an argument\n",
    "\n",
    "```\n",
    "seasonal_order=(1, 1, 0, 12)\n",
    "```\n",
    "\n",
    "along with the `order = (1, 0, 1)`.  For more information see the user guide from statsmodels [here](https://www.statsmodels.org/dev/examples/notebooks/generated/statespace_sarimax_stata.html).\n",
    "\n",
    "Below, build a `SARIMAX` estimator with the above order and seasonality and fit on the training data.  Assign the fit model to `sarima` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stores_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = stores_df['sales'].iloc[-700:-30], stores_df.iloc[-30:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6c457fdd0e9ef406",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "#NOTE: in your fit statement, use .fit(disp=0)\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "sarima = SARIMAX(X_train,  order=(1, 0, 1), seasonal_order=(1, 1, 0, 12)).fit(disp=0)\n",
    "### END SOLUTION\n",
    "\n",
    "### ANSWER CHECK\n",
    "sarima.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(X_train.index, sarima.predict())\n",
    "# plt.plot(X_train.index, X_train, alpha = 0.3)\n",
    "# plt.xticks(rotation = 60)\n",
    "# plt.title('The SARIMA Model')\n",
    "# plt.grid();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5307eb841aa55cfc",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "As you see, the SARIMA model can pick up the seasonal trends we have in this dataset.  You can also get a more sensitive ARMA model by using higher-order terms.  If you are interested in further work here, try grid-searching order and seasonality hyperparameters to determine the best model and order/seasonality parameters. \n",
    "\n",
    "Also, you can incorporate other features about the data as exogenous elements of both the ARMA and SARIMA models in statsmodels.  Consider trying engineering features with `ts_fresh` and using an exogenous model to see if this improves performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-92b1957d59812ed1",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Required Assignment 9.2: A First Look at the Ridge Regression Model\n",
    "\n",
    "\n",
    "**Expected Time: 45 Minutes**\n",
    "\n",
    "**Total Points: 30**\n",
    "\n",
    "This assignment introduces the `Ridge` regression estimator from scikit-learn.  You will revisit the insurance data from the previous assignment and experiment with varying the `alpha` parameter discussed in Video 9.4. Your work here is a basic introduction where complexity in the preprocessing steps will be added to scale your data.  For now, you are just to familiarize yourself with the `Ridge` regression estimator and its `alpha` parameter. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f129223b1962d630",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "#### Index\n",
    "\n",
    "- [Problem 1](#Problem-1)\n",
    "- [Problem 2](#Problem-2)\n",
    "- [Problem 3](#Problem-3)\n",
    "- [Problem 4](#Problem-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7d486c967d3f5fb9",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import set_config\n",
    "set_config(display=\"diagram\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-754c23ddd305c368",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### The Data: Insurance\n",
    "\n",
    "Below, the insurance data is loaded as train and test data with the cubic polynomial features created already.  Similarly, the transformed target feature is attached. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-bf5a026af8c18a19",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('data/train_cubic.csv')\n",
    "test_df = pd.read_csv('data/test_cubic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b6a4b9f20b933c7d",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>age^2</th>\n",
       "      <th>age bmi</th>\n",
       "      <th>age children</th>\n",
       "      <th>bmi^2</th>\n",
       "      <th>bmi children</th>\n",
       "      <th>children^2</th>\n",
       "      <th>age^3</th>\n",
       "      <th>age^2 bmi</th>\n",
       "      <th>age^2 children</th>\n",
       "      <th>age bmi^2</th>\n",
       "      <th>age bmi children</th>\n",
       "      <th>age children^2</th>\n",
       "      <th>bmi^3</th>\n",
       "      <th>bmi^2 children</th>\n",
       "      <th>bmi children^2</th>\n",
       "      <th>children^3</th>\n",
       "      <th>target_log</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>61.0</td>\n",
       "      <td>31.160</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3721.0</td>\n",
       "      <td>1900.760</td>\n",
       "      <td>0.0</td>\n",
       "      <td>970.945600</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>226981.0</td>\n",
       "      <td>115946.360</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59227.681600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30254.664896</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.505249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46.0</td>\n",
       "      <td>27.600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2116.0</td>\n",
       "      <td>1269.600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>761.760000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>97336.0</td>\n",
       "      <td>58401.600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35040.960000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21024.576000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.110666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54.0</td>\n",
       "      <td>31.900</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2916.0</td>\n",
       "      <td>1722.600</td>\n",
       "      <td>162.0</td>\n",
       "      <td>1017.610000</td>\n",
       "      <td>95.70</td>\n",
       "      <td>9.0</td>\n",
       "      <td>157464.0</td>\n",
       "      <td>93020.400</td>\n",
       "      <td>8748.0</td>\n",
       "      <td>54950.940000</td>\n",
       "      <td>5167.8</td>\n",
       "      <td>486.0</td>\n",
       "      <td>32461.759000</td>\n",
       "      <td>3052.8300</td>\n",
       "      <td>287.10</td>\n",
       "      <td>27.0</td>\n",
       "      <td>10.215511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>55.0</td>\n",
       "      <td>30.685</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3025.0</td>\n",
       "      <td>1687.675</td>\n",
       "      <td>0.0</td>\n",
       "      <td>941.569225</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>166375.0</td>\n",
       "      <td>92822.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51786.307375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28892.051669</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.652653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25.0</td>\n",
       "      <td>45.540</td>\n",
       "      <td>2.0</td>\n",
       "      <td>625.0</td>\n",
       "      <td>1138.500</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2073.891600</td>\n",
       "      <td>91.08</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15625.0</td>\n",
       "      <td>28462.500</td>\n",
       "      <td>1250.0</td>\n",
       "      <td>51847.290000</td>\n",
       "      <td>2277.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>94445.023464</td>\n",
       "      <td>4147.7832</td>\n",
       "      <td>182.16</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.648117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age     bmi  children   age^2   age bmi  age children        bmi^2  \\\n",
       "0  61.0  31.160       0.0  3721.0  1900.760           0.0   970.945600   \n",
       "1  46.0  27.600       0.0  2116.0  1269.600           0.0   761.760000   \n",
       "2  54.0  31.900       3.0  2916.0  1722.600         162.0  1017.610000   \n",
       "3  55.0  30.685       0.0  3025.0  1687.675           0.0   941.569225   \n",
       "4  25.0  45.540       2.0   625.0  1138.500          50.0  2073.891600   \n",
       "\n",
       "   bmi children  children^2     age^3   age^2 bmi  age^2 children  \\\n",
       "0          0.00         0.0  226981.0  115946.360             0.0   \n",
       "1          0.00         0.0   97336.0   58401.600             0.0   \n",
       "2         95.70         9.0  157464.0   93020.400          8748.0   \n",
       "3          0.00         0.0  166375.0   92822.125             0.0   \n",
       "4         91.08         4.0   15625.0   28462.500          1250.0   \n",
       "\n",
       "      age bmi^2  age bmi children  age children^2         bmi^3  \\\n",
       "0  59227.681600               0.0             0.0  30254.664896   \n",
       "1  35040.960000               0.0             0.0  21024.576000   \n",
       "2  54950.940000            5167.8           486.0  32461.759000   \n",
       "3  51786.307375               0.0             0.0  28892.051669   \n",
       "4  51847.290000            2277.0           100.0  94445.023464   \n",
       "\n",
       "   bmi^2 children  bmi children^2  children^3  target_log  \n",
       "0          0.0000            0.00         0.0    9.505249  \n",
       "1          0.0000            0.00         0.0   10.110666  \n",
       "2       3052.8300          287.10        27.0   10.215511  \n",
       "3          0.0000            0.00         0.0   10.652653  \n",
       "4       4147.7832          182.16         8.0   10.648117  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4c9d0eb07c898ebe",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-90f7470ed99a2bd7",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Problem 1\n",
    "\n",
    "#### Train and Test data\n",
    "\n",
    "**5 Points**\n",
    "\n",
    "Use the `train_df` and `test_df` data to split the data into `X_train`, `X_test`, `y_train` and `y_test`.\n",
    "\n",
    "Remember that the `target_log` column is the target column for your model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-fb986d6b36cb029c",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "### GRADED\n",
    "X_train, X_test, y_train, y_test = '', '', '', ''\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "X_train = train_df.drop('target_log', axis = 1)\n",
    "X_test = test_df.drop('target_log', axis = 1)\n",
    "y_train = train_df['target_log']\n",
    "y_test = test_df['target_log']\n",
    "### END SOLUTION\n",
    "\n",
    "# Answer check\n",
    "print(type(X_train))\n",
    "print(type(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-71fddbde6386a7c7",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Problem 2\n",
    "\n",
    "#### Default `Ridge` model\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "Now, use the `Ridge` regressor with default settings to build your first model. To this regressor, chain a `fit()` function to  train your model using `X_train` and `y_train`. Assign the result to `model_1`.\n",
    "\n",
    "Next, assign `model_1` coefficients as an array to `model_1_coefs` below.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4bfff6579249e8e1",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "solve() got an unexpected keyword argument 'sym_pos'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m model_1_coefs \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m### BEGIN SOLUTION\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m model_1 \u001b[38;5;241m=\u001b[39m \u001b[43mRidge\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m model_1_coefs \u001b[38;5;241m=\u001b[39m model_1\u001b[38;5;241m.\u001b[39mcoef_\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m### END SOLUTION\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Answer check\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/berkeley_ai_ml-A8BYuT1H/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:1130\u001b[0m, in \u001b[0;36mRidge.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1121\u001b[0m _accept_sparse \u001b[38;5;241m=\u001b[39m _get_valid_accept_sparse(sparse\u001b[38;5;241m.\u001b[39missparse(X), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msolver)\n\u001b[1;32m   1122\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[1;32m   1123\u001b[0m     X,\n\u001b[1;32m   1124\u001b[0m     y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1128\u001b[0m     y_numeric\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   1129\u001b[0m )\n\u001b[0;32m-> 1130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/berkeley_ai_ml-A8BYuT1H/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:889\u001b[0m, in \u001b[0;36m_BaseRidge.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    885\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    886\u001b[0m         \u001b[38;5;66;03m# for dense matrices or when intercept is set to 0\u001b[39;00m\n\u001b[1;32m    887\u001b[0m         params \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 889\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter_ \u001b[38;5;241m=\u001b[39m \u001b[43m_ridge_regression\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    891\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    892\u001b[0m \u001b[43m        \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    893\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    894\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    895\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    896\u001b[0m \u001b[43m        \u001b[49m\u001b[43msolver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msolver\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    897\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpositive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpositive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    898\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    899\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_n_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    900\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_intercept\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    901\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    902\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_intercept\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_intercept\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    903\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    904\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    905\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_intercept(X_offset, y_offset, X_scale)\n\u001b[1;32m    907\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/berkeley_ai_ml-A8BYuT1H/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:699\u001b[0m, in \u001b[0;36m_ridge_regression\u001b[0;34m(X, y, alpha, sample_weight, solver, max_iter, tol, verbose, positive, random_state, return_n_iter, return_intercept, X_scale, X_offset, check_input, fit_intercept)\u001b[0m\n\u001b[1;32m    697\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    698\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 699\u001b[0m         coef \u001b[38;5;241m=\u001b[39m \u001b[43m_solve_cholesky\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m linalg\u001b[38;5;241m.\u001b[39mLinAlgError:\n\u001b[1;32m    701\u001b[0m         \u001b[38;5;66;03m# use SVD solver if matrix is singular\u001b[39;00m\n\u001b[1;32m    702\u001b[0m         solver \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msvd\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/berkeley_ai_ml-A8BYuT1H/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:212\u001b[0m, in \u001b[0;36m_solve_cholesky\u001b[0;34m(X, y, alpha)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m one_alpha:\n\u001b[1;32m    211\u001b[0m     A\u001b[38;5;241m.\u001b[39mflat[:: n_features \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m alpha[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 212\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mXy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msym_pos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverwrite_a\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    214\u001b[0m     coefs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty([n_targets, n_features], dtype\u001b[38;5;241m=\u001b[39mX\u001b[38;5;241m.\u001b[39mdtype)\n",
      "\u001b[0;31mTypeError\u001b[0m: solve() got an unexpected keyword argument 'sym_pos'"
     ]
    }
   ],
   "source": [
    "### GRADED\n",
    "\n",
    "model_1 = ''\n",
    "model_1_coefs = ''\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "model_1 = Ridge().fit(X_train, y_train)\n",
    "model_1_coefs = model_1.coef_\n",
    "### END SOLUTION\n",
    "\n",
    "# Answer check\n",
    "print(f'Ridge Coefs: {np.round(model_1_coefs, 2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-35e1dccf86090101",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Problem 3\n",
    "\n",
    "#### Exploring different `alpha` values\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "Below, a list of alpha values is given to you. Define a `for` loop to iterate over the list `alphas` to create and train different Ridge models.\n",
    "\n",
    "Append the coefficients of each Ridge model as a list to `coef_list` below.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-161a0980f7a89db0",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "alphas = [0.001, 1.0, 10.0, 100.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2bb704d05a32d574",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "coef_list = []\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "for alpha in alphas:\n",
    "    ridge = Ridge(alpha = alpha)\n",
    "    ridge.fit(X_train, y_train)\n",
    "    coef_list.append(list(ridge.coef_))\n",
    "### END SOLUTION\n",
    "\n",
    "# Answer check\n",
    "len(coef_list)\n",
    "print('For alpha = 100 we have the following coefficients:')\n",
    "list(zip(X_train.columns, coef_list[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-813209f77b1b76ce",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Problem 4\n",
    "\n",
    "#### Exploring the coefficient for `children`\n",
    "\n",
    "**5 Points**\n",
    "\n",
    "To see the effect of varying alpha, you are to focus on the coefficients of the `children` feature.  Use the code `list([i[2] for i in coef_list])` to assign those values as a list to `child_coefs` below, building models on the given list of alphas.   \n",
    "\n",
    "In general, as you increase `alpha` what happens to the value of the coefficient -- `increase`, `decrease`, or `neither`?  Assign your answer as a string to `ans4` below. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e188ce51fa9f0f0c",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "\n",
    "child_coefs = ''\n",
    "ans4 = ''\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "child_coefs = list([i[2] for i in coef_list])\n",
    "ans4 = 'decrease'\n",
    "### END SOLUTION\n",
    "\n",
    "print(type(child_coefs))\n",
    "print(ans4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

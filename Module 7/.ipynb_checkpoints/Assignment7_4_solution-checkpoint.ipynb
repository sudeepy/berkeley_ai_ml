{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-85c5ca4ac4fdd93e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Required Codio Assignment 7.4: Using Non-Numeric Features \n",
    "\n",
    "**Expected Time = 90 minutes**\n",
    "\n",
    "**Total Points = 36**\n",
    "\n",
    "This activity focuses on making use of features that are categorical.  \n",
    "\n",
    "In this activity, you will explore the dummy encoding process to build and compare different regression models.  Specifically, you will use the sklearn estimator `LinearRegression`  to fit your models.  This model implements the mean squared error returning parameters that minimize the  loss. \n",
    "\n",
    "## Index:\n",
    "\n",
    "- [Problem 1](#Problem-1)\n",
    "- [Problem 2](#Problem-2)\n",
    "- [Problem 3](#Problem-3)\n",
    "- [Problem 4](#Problem-4)\n",
    "- [Problem 5](#Problem-5)\n",
    "- [Problem 6](#Problem-6)\n",
    "- [Problem 7](#Problem-8)\n",
    "- [Problem 8](#Problem-8)\n",
    "- [Problem 9](#Problem-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9a22d5a437dd7ab4",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### The Dataset\n",
    "\n",
    "The `diamonds` dataset from Seaborn is loaded and displayed below.  You will explore models that use both the `cut` and `color` features independently and models using all possible features.  To begin, you will use pandas `get_dummies` function to produce the dummy encoded data.  Your dummy encoded data should have as many features as there are unique values in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "\n",
    "diamonds = None\n",
    "\n",
    "try:\n",
    "    diamonds = sns.load_dataset('diamonds')\n",
    "except:\n",
    "    diamonds_dataset_uri = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/diamonds.csv\"\n",
    "    with urllib.request.urlopen(diamonds_dataset_uri) as response:\n",
    "        diamonds = pd.read_csv(response) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diamonds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-433af2323ef1dfc5",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#Index:) \n",
    "\n",
    "## Problem 1\n",
    "\n",
    "### Unique Values in `cut` and `color`\n",
    "\n",
    "**4 Points**\n",
    "\n",
    "Using the `cut` and `color` columns, determine the number of unique values in each column.  Assign the number of unique values in each feature as integers to `num_cuts` and `num_color` below.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-8e5fa6c3a595bfb3",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "\n",
    "num_cuts = ''\n",
    "num_color = ''\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "num_cuts = 5\n",
    "num_color = 7\n",
    "### END SOLUTION\n",
    "\n",
    "# Answer check\n",
    "print(num_cuts)\n",
    "print(num_color)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-cb59771f21acd91e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#Index:) \n",
    "\n",
    "## Problem 2\n",
    "\n",
    "### Encoding the `cut` column\n",
    "\n",
    "**4 Points**\n",
    "\n",
    "Use the `get_dummies()` function to create a dummy encoded version of the `cut` column.  Assign your encoded data as a DataFrame to the variable `cut_encoded` below.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7ee4b37394ca5e0f",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "\n",
    "cut_encoded = ''\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "cut_encoded = pd.get_dummies(diamonds[['cut']])\n",
    "### END SOLUTION\n",
    "\n",
    "# Answer check\n",
    "print(cut_encoded.shape)\n",
    "print(type(cut_encoded))\n",
    "cut_encoded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b936b27d27de6bc5",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#Index:) \n",
    "\n",
    "## Problem 3\n",
    "\n",
    "### A Regression model on `cut`\n",
    "\n",
    "**4 Points**\n",
    "\n",
    "Use the `get_dummies()` function to create a dummy encoded version of the `cut` column and assign the result to the variable `X`.\n",
    "\n",
    "To the variable `y`, assign the column `price` in the `diamonds` dataset.\n",
    "\n",
    "Use the `LinearRegression` estimator  with argument `fit_intercept = False` to build a regression model. Next, use the `fit()` function with arguments `X` and `y`  to predict the `price` column.  \n",
    "\n",
    "Assign the model to `cut_linreg` below.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b358a2033a89f85b",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "\n",
    "X = ''\n",
    "y = ''\n",
    "cut_linreg = ''\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "X = pd.get_dummies(diamonds[['cut']])\n",
    "y = diamonds['price']\n",
    "cut_linreg = LinearRegression(fit_intercept=False).fit(X, y)\n",
    "### END SOLUTION\n",
    "\n",
    "# Answer check\n",
    "print(cut_linreg)\n",
    "print(type(cut_linreg))\n",
    "cut_linreg.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-80de024ca4cb5a11",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#Index:) \n",
    "\n",
    "## Problem 4\n",
    "\n",
    "### Interpreting the results\n",
    "\n",
    "**4 Points**\n",
    "\n",
    "Compare the coefficients of the model.  Which cut does your model predict as the price for a diamond with an `ideal_cut`?  Assign your solution as a float rounded to two decimal places to `ideal_cut_prediction` below.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b06b47089c12434d",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "\n",
    "ideal_cut_prediction = ''\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "X = pd.get_dummies(diamonds[['cut']])\n",
    "y = diamonds['price']\n",
    "cut_linreg = LinearRegression(fit_intercept=False).fit(X, y)\n",
    "ideal_cut_prediction = float(round(cut_linreg.coef_[0], 2))\n",
    "### END SOLUTION\n",
    "\n",
    "# Answer check\n",
    "print(ideal_cut_prediction)\n",
    "print(type(ideal_cut_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7371ae08b020d01a",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#Index:) \n",
    "\n",
    "## Problem 5\n",
    "\n",
    "### Building a model on `clarity`\n",
    "\n",
    "**4 Points**\n",
    "\n",
    "Use the `get_dummies()` function to create a dummy encoded version of the `clarity` column and assign the result to the variable `X`.\n",
    "\n",
    "To the variable `y`, assign the column `price` in the `diamonds` dataset.\n",
    "\n",
    "Use the `LinearRegression` estimator  with argument `fit_intercept = False` to build a regression model. Next, use the `fit()` function with arguments `X` and `y`  to predict the `price` column.  \n",
    "\n",
    "Assign the model to `clarity_linreg` below.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d41dca4e4100c34f",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "\n",
    "X = ''\n",
    "y = ''\n",
    "clarity_linreg = ''\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "X = pd.get_dummies(diamonds[['clarity']])\n",
    "y = diamonds['price']\n",
    "clarity_linreg = LinearRegression(fit_intercept=False).fit(X, y)\n",
    "### END SOLUTION\n",
    "\n",
    "# Answer check\n",
    "print(clarity_linreg.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-3845e5df873e1c54",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#Index:) \n",
    "\n",
    "## Problem 6\n",
    "\n",
    "### Interpreting the results\n",
    "\n",
    "**4 Points**\n",
    "\n",
    "Examine your coefficients and compare these to the columns of the dummy encoded version of the `clarity` column.  What price does your model predict for a diamond with clarity `SI2`?  Assign your results as a float rounded to 2 decimal places to `clarity_si2_prediction`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f6e64773ce4b97fb",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "\n",
    "clarity_si2_prediction = ''\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "X = pd.get_dummies(diamonds[['clarity']])\n",
    "y = diamonds['price']\n",
    "cut_linreg = LinearRegression(fit_intercept=False).fit(X, y)\n",
    "clarity_si2_prediction = float(round(cut_linreg.coef_[-2], 2))\n",
    "### END SOLUTION\n",
    "\n",
    "# Answer check\n",
    "print(clarity_si2_prediction)\n",
    "print(type(clarity_si2_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1503d361107d5737",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#Index:) \n",
    "\n",
    "## Problem 7\n",
    "\n",
    "### A Model with `cut`, `clarity`, and `carat`\n",
    "\n",
    "**4 Points**\n",
    "\n",
    "Use the `get_dummies()` function to create a dummy encoded version of the `carat`, `cut`, and `clarity` columns and assign the result to the variable `X`.\n",
    "\n",
    "To the variable `y`, assign the column `price` in the `diamonds` dataset.\n",
    "\n",
    "Use the `LinearRegression` estimator  with argument `fit_intercept = False` to build a regression model. Next, use the `fit()` function with arguments `X` and `y`  to predict the `price` column.  \n",
    "\n",
    "Assign the model to `ccc_linreg` below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-063059f3fd3d52f3",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "\n",
    "ccc_linreg = ''\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "X = pd.get_dummies(diamonds[['carat', 'cut', 'clarity']])\n",
    "y = diamonds['price']\n",
    "ccc_linreg = LinearRegression(fit_intercept=False).fit(X, y)\n",
    "### END SOLUTION\n",
    "\n",
    "# Answer check\n",
    "print(ccc_linreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f5d2f09c43dabe68",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#Index:) \n",
    "\n",
    "## Problem 8\n",
    "\n",
    "### Interpreting the results\n",
    "\n",
    "**4 Points**\n",
    "\n",
    "Examine the coefficients from the model and use them to determine the predicted price of a diamond with the following features:\n",
    "\n",
    "```\n",
    "carat = 0.8\n",
    "cut = Ideal\n",
    "clarity = SI2\n",
    "```\n",
    "\n",
    "Assign your solution as a float rounded to two decimal places to the variable `ccc_prediction` below.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-dc810ef233e9b1e8",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "\n",
    "ccc_prediction = ''\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "diamonds_encoded = pd.get_dummies(diamonds[['carat', 'cut', 'clarity']])\n",
    "\n",
    "diamond_features = pd.DataFrame({\n",
    "    'carat': [0.8],\n",
    "    'cut': ['Ideal'],\n",
    "    'clarity': ['SI2']\n",
    "})\n",
    "\n",
    "diamond_features_encoded = pd.get_dummies(diamond_features).reindex(columns=diamonds_encoded.columns, fill_value=0)\n",
    "\n",
    "ccc_linreg = LinearRegression(fit_intercept=False).fit(diamonds_encoded, diamonds['price'])\n",
    "\n",
    "ccc_prediction = ccc_linreg.predict(diamond_features_encoded)\n",
    "\n",
    "ccc_prediction = round(ccc_prediction[0], 2)\n",
    "\n",
    "\n",
    "### END SOLUTION\n",
    "\n",
    "# Answer check\n",
    "print(ccc_prediction)\n",
    "print(type(ccc_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a10b65e7e86fda15",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#Index:) \n",
    "\n",
    "## Problem 9\n",
    "\n",
    "### A Model with all features\n",
    "\n",
    "**4 Points**\n",
    "\n",
    "Use the `get_dummies()` function to create a dummy encoded version of all the columns in the `diamonds` DataFrame except for the column `price` and assign the result to the variable `X`.\n",
    "\n",
    "To the variable `y`, assign the column `price` in the `diamonds` dataset.\n",
    "\n",
    "Use the `LinearRegression` estimator  with argument `fit_intercept = False` to build a regression model. Next, use the `fit()` function with arguments `X` and `y`  to predict the `price` column.  \n",
    "\n",
    "Assign the model to `all_features_linreg` below. \n",
    "\n",
    "Use the `mean_squared_error` function to compute the MSE between `all_features_linreg.predict(X)` and `y`. Assign the result to `linreg_mse` below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1e23dad455d8e668",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "\n",
    "X = ''\n",
    "y = ''\n",
    "all_features_linreg = ''\n",
    "linreg_mse = ''\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "X = pd.get_dummies(diamonds.drop('price', axis = 1))\n",
    "y = diamonds['price']\n",
    "all_features_linreg = LinearRegression(fit_intercept=False).fit(X, y)\n",
    "linreg_mse = mean_squared_error(all_features_linreg.predict(X), y)\n",
    "### END SOLUTION\n",
    "\n",
    "# Answer check\n",
    "print(all_features_linreg)\n",
    "print(all_features_linreg.coef_)\n",
    "print(linreg_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-89af5c8ab4476bc5",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Conclusion\n",
    "\n",
    "While some basic initial models have been explored here, there is much more to explore to fine-tune things. One thing that could be revisited is the representation of features through transformations and the engineering of different representations of existing features.  For example, the dimensions of the diamond in `x`, `y`, and `z` could be multiplied to create a feature \"volume\".  This allows for a more reasonable representation of three columns of data with one.  A second approach we might take is to use PCA to reduce the dimensionality of the data.  The third is to use clustering to engineer new features based on the cluster results.  Consider exploring different representations of the features and trying to improve these initial models."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
